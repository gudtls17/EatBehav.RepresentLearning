{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brave-black",
   "metadata": {},
   "source": [
    "# Brain visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subcortical visualization\n",
    "from enigmatoolbox.plotting import plot_subcortical\n",
    "\n",
    "# orig_sctx_list = ['Amygdala','Hippocampus','Caudate','Pallidum','Accumbens','Putamen','Thalamus'];\n",
    "# reorder_sctx_list = ['Accumbens', 'Amygdala', 'Caudate', 'Hippocampus', 'Pallidum', 'Putamen','Thalamus', 'Ventricle];\n",
    "# L to R\n",
    "# if True include ventricle [1x16] else except [1x14];\n",
    "\n",
    "ANOVA_DC_f_123_sctx = np.load(join(main_path, 'result/latent_210/main_result/subcortical','ANOVA_DC_f_123_sctx.npy'))\n",
    "\n",
    "DC_sub1_mean_Msctx2ctx_regout = np.load(join(main_path, 'result/latent_210/main_result/subcortical','DC_sub1_mean_Msctx2ctx_regout.npy'))\n",
    "DC_sub2_mean_Msctx2ctx_regout = np.load(join(main_path, 'result/latent_210/main_result/subcortical','DC_sub2_mean_Msctx2ctx_regout.npy'))\n",
    "DC_sub3_mean_Msctx2ctx_regout = np.load(join(main_path, 'result/latent_210/main_result/subcortical','DC_sub3_mean_Msctx2ctx_regout.npy'))\n",
    "  \n",
    "\n",
    "f_data = np.array(list(ANOVA_DC_f_123_sctx[[4,0,2,1,3,5,6]]) + list(ANOVA_DC_f_123_sctx[[4,0,2,1,3,5,6]]))\n",
    "dc_sub1 = np.array(list(DC_sub1_mean_Msctx2ctx_regout[[4,0,2,1,3,5,6]]) + list(DC_sub1_mean_Msctx2ctx_regout[[4,0,2,1,3,5,6]]))\n",
    "dc_sub2 = np.array(list(DC_sub2_mean_Msctx2ctx_regout[[4,0,2,1,3,5,6]]) + list(DC_sub2_mean_Msctx2ctx_regout[[4,0,2,1,3,5,6]]))\n",
    "dc_sub3 = np.array(list(DC_sub3_mean_Msctx2ctx_regout[[4,0,2,1,3,5,6]]) + list(DC_sub3_mean_Msctx2ctx_regout[[4,0,2,1,3,5,6]]))\n",
    "\n",
    "plot_target = 'base_region' # f, DC, base_region\n",
    "\n",
    "# Project the results on the surface brain\n",
    "\n",
    "if plot_target == 'f':\n",
    "    # f-stat\n",
    "    plot_subcortical(array_name=f_data, size=(1600, 400), ventricles = False, cmap='autumn', color_bar=True, color_range=(8, 18)) # viridis autumn\n",
    "elif plot_target == 'DC':\n",
    "    # Subgroup DC\n",
    "    plot_subcortical(array_name=dc_sub2, size=(1600, 400), ventricles = False, cmap='viridis_r', color_bar=True) # viridis Reds\n",
    "    \n",
    "elif plot_target =='base_region':\n",
    "    def base_region(name):\n",
    "        region = np.zeros(14)\n",
    "        region[name]=1\n",
    "        \n",
    "        return region\n",
    "    \n",
    "    Accumbens = [0,7]\n",
    "    Amygdala = [1,8] \n",
    "    Caudate = [2,9]\n",
    "    Hippocampus = [3,10]\n",
    "    Pallidum = [4,11]\n",
    "    Putamen = [5,12]\n",
    "    Thalamus = [6,13]\n",
    "    \n",
    "    region_data = base_region(Accumbens)\n",
    "    \n",
    "    plot_subcortical(array_name=region_data, size=(1600, 400), ventricles = False, cmap='Greys', color_bar=True, color_range = (-0.2,1)) # viridis autumn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare visualization\n",
    "\n",
    "import vtk\n",
    "\n",
    "from vtk import vtkPolyDataNormals\n",
    "\n",
    "from brainspace.mesh.mesh_io import read_surface\n",
    "from brainspace.mesh.mesh_operations import combine_surfaces\n",
    "from brainspace.utils.parcellation import reduce_by_labels\n",
    "from brainspace.vtk_interface import wrap_vtk, serial_connect\n",
    "\n",
    "template_path = join(main_path,\"template/MMP\")\n",
    "template_L = \"L.very_inflated_MSMAll.10k_fs_LR.surf.gii\" # S900.L.midthickness_MSMAll.10k_fs_LR.surf.gii # L.very_inflated_MSMAll.10k_fs_LR.surf.gii\n",
    "template_R = \"R.very_inflated_MSMAll.10k_fs_LR.surf.gii\" # S900.R.midthickness_MSMAll.10k_fs_LR.surf.gii # R.very_inflated_MSMAll.10k_fs_LR.surf.gii\n",
    "\n",
    "surfs = [None] * 2\n",
    "\n",
    "surfs[0] = read_surface(join(template_path,template_L)) \n",
    "nf = wrap_vtk(vtkPolyDataNormals, splitting=False, featureAngle=0.1)\n",
    "surf_lh = serial_connect(surfs[0], nf)\n",
    "\n",
    "surfs[1] = read_surface(join(template_path,template_R)) \n",
    "nf = wrap_vtk(vtkPolyDataNormals, splitting=False, featureAngle=0.1)\n",
    "surf_rh = serial_connect(surfs[1], nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "from brainspace.datasets import load_group_fc, load_parcellation, load_conte69\n",
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.plotting import plot_hemispheres\n",
    "from brainspace.utils.parcellation import map_to_labels\n",
    "\n",
    "\n",
    "atlas = parc \n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "labeling = atlas #load_parcellation('schaefer', scale=300, join=True) # total_label # load_parcellation('schaefer', scale=300, join=True)\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "conn_matrix1 = IG1_testmean \n",
    "conn_matrix2 = IG2_testmean\n",
    "conn_matrix3 = IG3_testmean\n",
    "# conn_matrix4 = sub3_choice[3]\n",
    "# conn_matrix5 = sub3_choice[4]\n",
    "\n",
    "\n",
    "mask = labeling != 0\n",
    "\n",
    "grad1 = map_to_labels(conn_matrix1, labeling, mask=mask, fill=np.nan) # fill = np.nan fill = 0\n",
    "grad2 = map_to_labels(conn_matrix2, labeling, mask=mask, fill=np.nan)\n",
    "grad3 = map_to_labels(conn_matrix3, labeling, mask=mask, fill=np.nan)\n",
    "# grad4 = map_to_labels(conn_matrix4, labeling, mask=mask, fill=np.nan)\n",
    "# grad5 = map_to_labels(conn_matrix5, labeling, mask=mask, fill=np.nan)\n",
    "\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=[grad1, grad2, grad3], size=(1300, 900), color_bar=True, cmap='viridis', zoom=1.25, nan_color=(0,0,0,1) , color_range=(-0.05,0.05) ) # parula_map, 'jet' # 'viridis', 'Blues', 'Reds', 'seismic' # color_range = (-0.1,0.16) # color_range = (-13,13) nan_color=(0.8,0.8,0.8,1)\n",
    "                                                                                                                 # view = None 'dorsal' 'ventral'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-satellite",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spider plot (Radar plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-converter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_work = join(main_path,'result/latent_210')\n",
    "\n",
    "yeo7net_withSub_label = np.load(join(path_work, 'main_result', 'AE', 'BNA2yeo7.npy'), allow_pickle = True).item()['Label_name']\n",
    "BNA2yeo7_withSub_idx = np.load(join(path_work, 'main_result', 'AE', 'BNA2yeo7.npy'), allow_pickle = True).item()['BNA2yeo7_withSub_idx']\n",
    "\n",
    "yeo7net = yeo7net_withSub_label[:7]\n",
    "BNA2yeo7 = BNA2yeo7_withSub_idx[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_region(name):\n",
    "        region = np.zeros(246)\n",
    "        region[name]=1\n",
    "        \n",
    "        return region\n",
    "    \n",
    "visual_BNA = base_region(np.where(BNA2yeo7_withSub_idx==0))\n",
    "somatomotor_BNA = base_region(np.where(BNA2yeo7_withSub_idx==1))\n",
    "D_attention_BNA = base_region(np.where(BNA2yeo7_withSub_idx==2))\n",
    "V_attention_BNA = base_region(np.where(BNA2yeo7_withSub_idx==3))\n",
    "limbic_BNA = base_region(np.where(BNA2yeo7_withSub_idx==4))\n",
    "frontoparietal_BNA = base_region(np.where(BNA2yeo7_withSub_idx==5))\n",
    "default_BNA = base_region(np.where(BNA2yeo7_withSub_idx==6))\n",
    "\n",
    "net_list = [visual_BNA, somatomotor_BNA, D_attention_BNA, V_attention_BNA, limbic_BNA, frontoparietal_BNA, default_BNA]\n",
    "\n",
    "for i in range(7):\n",
    "    np.save(join(main_path,'result/latent_210', 'main_result/AE', 'Yeo7net',yeo7net_withSub_label[i]+'_BNA.npy'),net_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IG MANOVA result plot\n",
    "\n",
    "grad1_testmean = np.load(join(main_path,'result/latent_210','main_result/AE','grad1_testmean.npy'))\n",
    "grad2_testmean = np.load(join(main_path,'result/latent_210','main_result/AE','grad2_testmean.npy'))\n",
    "grad3_testmean = np.load(join(main_path,'result/latent_210','main_result/AE','grad3_testmean.npy'))\n",
    "\n",
    "MANOVA_IG_f_123_rmsubcor = np.load(join(main_path,'result/latent_210','main_result/AE','IG', 'MANOVA_IG_f_123_rmsubcor.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-timothy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_list = ['MANOVA_f_123_rmsubcor.npy', 'MANOVA_t_12_rmsubcor.npy', 'MANOVA_t_13_rmsubcor.npy', 'MANOVA_t_23_rmsubcor.npy']\n",
    "# data_list = ['MANOVA_f_123_whole_rmsubcor.npy', 'MANOVA_t_12_whole_rmsubcor.npy', 'MANOVA_t_13_whole_rmsubcor.npy', 'MANOVA_t_23_whole_rmsubcor.npy']\n",
    "# data_list = ['MANOVA_t_GradIG_rmsubcor.npy', 'MANOVA_t_GradIG_whole_rmsubcor.npy']\n",
    "# data_list = ['MANOVA_f_123_rmsubcor_fdr01.npy', 'MANOVA_t_12_rmsubcor_fdr01.npy', 'MANOVA_t_13_rmsubcor_fdr01.npy', 'MANOVA_t_23_rmsubcor_fdr01.npy'] # Lemon FDR 0.01\n",
    "# data_list = [DC_sub1_mean]#, DC_sub2_mean, DC_sub3_mean]\n",
    "# data_list = [ME_sub1_mean, ME_sub2_mean, ME_sub3_mean]\n",
    "data_list = [grad1_testmean, grad2_testmean, grad3_testmean] # For before Figure 2 supplement\n",
    "data_list = [MANOVA_IG_f_123_rmsubcor]\n",
    "\n",
    "for i in data_list:\n",
    "\n",
    "#     data = np.load(join(path_work, 'main_result/AE', f'{i}')) # for MANOVA\n",
    "    data = i # for DC\n",
    "    data_yeo = np.array([abs(data)[BNA2yeo7==i].mean() for i in range(BNA2yeo7.max()+1)])\n",
    "    print(data_yeo)\n",
    "    plot_spider(data_yeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spider(data_yeo):\n",
    "\n",
    "    from math import pi\n",
    "    from matplotlib.spines import Spine\n",
    "    from matplotlib.path import Path\n",
    "    from matplotlib.transforms import Affine2D\n",
    "\n",
    "    labels = yeo7net # label\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    angles = [x/float(num_labels)*(2*pi) for x in range(num_labels)] ## 각 등분점\n",
    "    angles += angles[:1] ## 시작점으로 다시 돌아와야하므로 시작점 추가\n",
    "    \n",
    "#     sns.set(style = 'white', font_scale=1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig.set_facecolor('white')\n",
    "    ax = fig.add_subplot(projection='polar')\n",
    "    \n",
    "    color = 'black'\n",
    "    data = data_yeo.tolist()\n",
    "    data += data[:1]\n",
    "\n",
    "    ax.set_theta_offset(pi / 2) ## 시작점\n",
    "    ax.set_theta_direction(-1) ## 그려지는 방향 시계방향\n",
    "\n",
    "    plt.xticks(angles[:-1], labels, fontsize=20) ## x축 눈금 라벨\n",
    "#     ax.tick_params(axis='x', which='major', pad=30) ## x축과 눈금 사이에 여백을 준다.\n",
    "    ax.tick_params(axis='x', which='both', labelbottom=False) ## Remove xticks\n",
    "\n",
    "    ax.set_rlabel_position(0) ## y축 각도 설정(degree 단위)\n",
    "    plt.yticks([5, 10, 15],['5','10','15'], fontsize=30) ## y축 눈금 설정\n",
    "    plt.ylim([5,20])    \n",
    "\n",
    "    ax.plot(angles, data, color=color, linewidth=3, linestyle='solid') ## 레이더 차트 출력\n",
    "    ax.fill(angles, data, color=color, alpha=0.4) ## 도형 안쪽에 색을 채워준다.\n",
    "    \n",
    "    for g in ax.yaxis.get_gridlines(): ## surround inner grid line \n",
    "        g.get_path()._interpolation_steps = len(labels)\n",
    "        g.set_linewidth(3)\n",
    "        \n",
    "        \n",
    "    for g in ax.xaxis.get_gridlines(): ## linear inner grid line \n",
    "        g.set_linewidth(3)\n",
    "        \n",
    "\n",
    "    spine = Spine(axes=ax, spine_type='circle', path=Path.unit_regular_polygon(len(labels))) # edge grid line\n",
    "    spine.set_linewidth(3)\n",
    "    spine.set_color('k')\n",
    " \n",
    "    ## Axes의 중심과 반지름을 맞춰준다.\n",
    "    spine.set_transform(Affine2D().scale(.5).translate(.5, .5)+ax.transAxes)\n",
    "    \n",
    "    ax.spines = {'polar':spine} ## frame의 모양을 원에서 폴리곤으로 바꿔줘야한다.    \n",
    "    \n",
    "#     plt.title('Spider test', size=20, color=color,x=-0.2, y=1.2, ha='left') ## 타이틀은 캐릭터 클래스로 한다.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-degree",
   "metadata": {},
   "source": [
    "# Compare discovery replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-uganda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save TFEQ score\n",
    "\n",
    "Main_AE_Score = DataFrame([BMI[main_otest_idx], TFEQ_F1[main_otest_idx], TFEQ_F2[main_otest_idx], TFEQ_F3[main_otest_idx]]).T\n",
    "Main_AE_Score.columns = ['BMI','TFEQ_F1','TFEQ_F2','TFEQ_F3']\n",
    "Main_AE_Score.reset_index(inplace=True)\n",
    "Main_AE_Score['Subtype'] = main_cluster_label\n",
    "Main_AE_Score\n",
    "# Main_AE_Score.to_excel(join(main_path,'result/latent_210/main_result/AE/Main_AE_Score.xlsx'), sheet_name = 'Sheet1', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comare eNKI / Lemon subtype score\n",
    "\n",
    "path_data = join(main_path,'result/latent_210')\n",
    "Main_AE_Score = pd.read_excel(join(path_data, 'main_result', 'AE', 'Main_AE_Score.xlsx'), sheet_name='Sheet1', skiprows=0)\n",
    "Lemon_Score = pd.read_excel(join(path_data, 'validation', 'Lemon_score.xlsx'), sheet_name='Sheet1', skiprows=0)\n",
    "\n",
    "Main_AE_Score['Dataset'] = 'Discovery'\n",
    "Lemon_Score['Dataset'] = 'Replication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_name = 'TFEQ_F3' # BMI TFEQ_F1 TFEQ_F2 TFEQ_F3\n",
    "df_ABD1 = DataFrame([Main_AE_Score[score_name], Main_AE_Score['Subtype'], Main_AE_Score['Dataset']]).T\n",
    "df_ABD2 = DataFrame([Lemon_Score[score_name], Lemon_Score['Subtype'], Lemon_Score['Dataset']]).T\n",
    "\n",
    "df_ABD12 = pd.concat([df_ABD1, df_ABD2], axis=0)\n",
    "\n",
    "df_plot = df_ABD12[df_ABD12[score_name]>0]\n",
    "\n",
    "plt.figure(1,(7,5))\n",
    "sns.set(style = 'whitegrid', font_scale=2.5)\n",
    "g = sns.pointplot(x = 'Subtype' , y = score_name, hue = 'Dataset', data = df_plot,  palette = \"gray\", plot_kws=dict(alpha=1))\n",
    "# plt.title(score_name, fontsize = 25)\n",
    "# plt.xlabel('Subtype', fontsize = 25)\n",
    "# plt.ylabel(score_name, fontsize = 25)\n",
    "plt.ylim([2,12]) # [18,33] # [2,12]\n",
    "plt.yticks([3,6,9,12]) # [20,24,28,32] # [3,6,9,12]\n",
    "plt.legend(fontsize = 20, loc = 'lower right')\n",
    "plt.legend([],[], frameon=False) # remove legend\n",
    "plt.setp(g.collections, alpha = 1)\n",
    "plt.setp(g.lines[1:4], alpha=.1)  \n",
    "plt.setp(g.lines[5:8], alpha=.1)  \n",
    "\n",
    "# sns.swarmplot(x = 'ASD Subtype' , y = 'ADOS Communication', data = df_plot, color = '.25')\n",
    "\n",
    "is_Dis = df_plot['Dataset'] == 'Discovery'\n",
    "is_Rep = df_plot['Dataset'] == 'Replication'\n",
    "is_sub1 = df_plot['Subtype'] == 0\n",
    "is_sub2 = df_plot['Subtype'] == 1\n",
    "is_sub3 = df_plot['Subtype'] == 2\n",
    "\n",
    "chi_ob=[]\n",
    "chi_expect=[]\n",
    "\n",
    "for num in [is_sub1, is_sub2, is_sub3]:\n",
    "    print('p value : ',sc.stats.ttest_ind(df_plot[num & is_Dis][score_name],df_plot[num & is_Rep][score_name])[1])\n",
    "    print('Discovery score : ',df_plot[num & is_Dis][score_name].mean(),' +- ',df_plot[num & is_Dis][score_name].std())\n",
    "    print('Replication score : ',df_plot[num & is_Rep][score_name].mean(),' +- ',df_plot[num & is_Rep][score_name].std())\n",
    "    print(' ')\n",
    "    chi_expect.append(df_plot[num & is_Dis][score_name].mean())\n",
    "    chi_ob.append(df_plot[num & is_Rep][score_name].mean())\n",
    "\n",
    "# Chi square test between Discovery and Replication\n",
    "print(chi_ob)\n",
    "print(chi_expect)\n",
    "\n",
    "chi_stat, chi_pval = sc.stats.chisquare(chi_ob, f_exp=chi_expect, axis=None, ddof = [0,1,2])\n",
    "\n",
    "print('')\n",
    "print(chi_stat)\n",
    "print(chi_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-humor",
   "metadata": {},
   "source": [
    "# Utils (def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-entity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find significant different latent feature element from each subtype\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "def latent_sig_elem_ttest(input_a,input_b, k):\n",
    "    [s,p] = sc.stats.ttest_ind(input_a, input_b, axis=0, equal_var=False)\n",
    "    p_fdr = sm.stats.multitest.multipletests(p,alpha=0.001,method='fdr_bh')\n",
    "    sig_idx = np.where(p_fdr[0]==True)[0]\n",
    "    \n",
    "    cohens_d = s*np.sqrt(1/len(input_a)+1/len(input_b))\n",
    "\n",
    "    print('총', len(sig_idx), '개')\n",
    "\n",
    "    topk_idx = np.argsort(np.abs(s[sig_idx]))[-k:][::-1]\n",
    "    Cohend_large_idx = np.where(np.abs(cohens_d[sig_idx])>=1.2)[0]\n",
    "#     print(f'Very large effect size {len(Cohend_large_idx)}')\n",
    "    print(f'Cohen d value : {np.round(cohens_d[sig_idx],2)}') # cohens_d[sig_idx] cohens_d[sig_idx][Cohend_large_idx]\n",
    "    print(f'Region index : {sig_idx}') # sig_idx sig_idx[Cohend_large_idx] \n",
    "    \n",
    "    return sig_idx # sig_idx sig_idx[Cohend_large_idx]\n",
    "    \n",
    "def latent_sig_elem_anova(input_a,input_b, input_c, k):\n",
    "    [s,p] = sc.stats.f_oneway(input_a, input_b, input_c)\n",
    "    p_fdr = sm.stats.multitest.multipletests(p,alpha=0.05,method='fdr_bh')\n",
    "    sig_idx = np.where(p_fdr[0]==True)[0]\n",
    "    \n",
    "    print(len(sig_idx), '개')\n",
    "\n",
    "    topk_idx = np.argsort(np.abs(s[sig_idx]))[-k:][::-1]\n",
    "    print(f'Top {k} Statistic value : {np.round(s[sig_idx][topk_idx],2)}')\n",
    "    print(f'Top {k} Region index : {sig_idx[topk_idx]}')\n",
    "    \n",
    "    return sig_idx[topk_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-monthly",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def output2numpy(result1,result2,result3):\n",
    "\n",
    "    result1 = torch.cat(result1).detach().cpu().numpy()\n",
    "    result2 = torch.cat(result2).detach().cpu().numpy()\n",
    "    result3 = torch.cat(result3).detach().cpu().numpy()\n",
    "\n",
    "    return result1, result2, result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-pleasure",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subtype Score Plot\n",
    "\n",
    "def score_plot(trial, otest_idx, cluster_label, save=True, plot_close=True):\n",
    "\n",
    "    import seaborn as sns\n",
    "\n",
    "#     y = TFEQ_F3 # BMI WHR EDE_Q_R EDE_Q_con EDE_Q_E_con EDE_Q_S_con EDE_Q_W_con TFEQ_F1 TFEQ_F2 TFEQ_F3 \n",
    "\n",
    "    idx = otest_idx # itrain_idx itest_idx otest_idx\n",
    "\n",
    "    df = pd.DataFrame([np.array(BMI)[idx], np.array(WHR)[idx], np.array(EDE_Q_R)[idx], np.array(EDE_Q_con)[idx], np.array(EDE_Q_E_con)[idx], np.array(EDE_Q_S_con)[idx], \n",
    "                       np.array(EDE_Q_W_con)[idx], np.array(TFEQ_F1)[idx], np.array(TFEQ_F2)[idx], np.array(TFEQ_F3)[idx], cluster_label]) # cluster_labels  label_manual\n",
    "    df = df.T\n",
    "    df.columns = ['BMI','WHR','EDE_Q_R','EDE_Q_con','EDE_Q_E_con','EDE_Q_S_con','EDE_Q_W_con','TFEQ_F1','TFEQ_F2','TFEQ_F3','Subtype']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(30, 10))\n",
    "\n",
    "    sns.set(style = 'whitegrid', font_scale=1.0)\n",
    "    sns.boxplot(ax = axes[0,0], x = 'Subtype' , y = 'BMI', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[0,0], x = 'Subtype' , y = 'BMI', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[0,1], x = 'Subtype' , y = 'WHR', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[0,1], x = 'Subtype' , y = 'WHR', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[0,2], x = 'Subtype' , y = 'EDE_Q_R', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[0,2], x = 'Subtype' , y = 'EDE_Q_R', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[0,3], x = 'Subtype' , y = 'EDE_Q_con', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[0,3], x = 'Subtype' , y = 'EDE_Q_con', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[0,4], x = 'Subtype' , y = 'EDE_Q_E_con', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[0,4], x = 'Subtype' , y = 'EDE_Q_E_con', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[1,0], x = 'Subtype' , y = 'EDE_Q_S_con', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[1,0], x = 'Subtype' , y = 'EDE_Q_S_con', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[1,1], x = 'Subtype' , y = 'EDE_Q_W_con', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[1,1], x = 'Subtype' , y = 'EDE_Q_W_con', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[1,2], x = 'Subtype' , y = 'TFEQ_F1', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[1,2], x = 'Subtype' , y = 'TFEQ_F1', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[1,3], x = 'Subtype' , y = 'TFEQ_F2', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[1,3], x = 'Subtype' , y = 'TFEQ_F2', data = df, color = 'k', size = 4)\n",
    "\n",
    "    sns.boxplot(ax = axes[1,4], x = 'Subtype' , y = 'TFEQ_F3', data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(ax = axes[1,4], x = 'Subtype' , y = 'TFEQ_F3', data = df, color = 'k', size = 4)\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(join(save_path,trial,'score_plot.png'))\n",
    "        \n",
    "    if plot_close:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-soldier",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stat_result(trial, otest_idx, cluster_label, save=True, result_show = True):\n",
    "\n",
    "    bmi = np.array(BMI)\n",
    "    whr = np.array(WHR)\n",
    "    e_r = np.array(EDE_Q_R)\n",
    "    e_c = np.array(EDE_Q_con)\n",
    "    e_ec = np.array(EDE_Q_E_con)\n",
    "    e_sc = np.array(EDE_Q_S_con)\n",
    "    e_wc = np.array(EDE_Q_W_con) \n",
    "    t_f1 = np.array(TFEQ_F1)\n",
    "    t_f2 = np.array(TFEQ_F2)\n",
    "    t_f3 = np.array(TFEQ_F3)\n",
    "\n",
    "    idx = otest_idx # itrain_idx itest_idx otest_idx\n",
    "    label = cluster_label # cluster_labels cluster_label label_manual\n",
    "\n",
    "    idx1 = idx[np.where(label==0)[0]]\n",
    "    idx2 = idx[np.where(label==1)[0]]\n",
    "    idx3 = idx[np.where(label==2)[0]]\n",
    "    idx4 = idx[np.where(label==3)[0]]\n",
    "    idx5 = idx[np.where(label==4)[0]]\n",
    "    idx6 = idx[np.where(label==5)[0]]\n",
    "\n",
    "    # Statistical test\n",
    "\n",
    "    import statsmodels as sm\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "    BMI_fdr = []\n",
    "    WHR_fdr = []\n",
    "    EDEQ_R_fdr = []\n",
    "    EDEQ_Con_fdr = []\n",
    "    EDEQ_E_Con_fdr = []\n",
    "    EDEQ_S_Con_fdr = []\n",
    "    EDEQ_W_Con_fdr = []\n",
    "    TFEQ_F1_fdr = []\n",
    "    TFEQ_F2_fdr = []\n",
    "    TFEQ_F3_fdr = []\n",
    "\n",
    "    idx_list1 = [idx1, idx1, idx2]\n",
    "    idx_list2 = [idx2, idx3, idx3]\n",
    "\n",
    "    for i in range(3):\n",
    "\n",
    "        a = idx_list1[i] # idx1 idx1 idx2\n",
    "        b = idx_list2[i] # idx2 idx3 idx3\n",
    "\n",
    "        [s_0,p_0] = sc.stats.ttest_ind(bmi[a], bmi[b], equal_var = False, axis=0)\n",
    "\n",
    "        [s_1,p_1] = sc.stats.ttest_ind(whr[a], whr[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_2,p_2] = sc.stats.ttest_ind(e_r[a], e_r[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_3,p_3] = sc.stats.ttest_ind(e_c[a], e_c[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_4,p_4] = sc.stats.ttest_ind(e_ec[a], e_ec[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_5,p_5] = sc.stats.ttest_ind(e_sc[a], e_sc[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_6,p_6] = sc.stats.ttest_ind(e_wc[a], e_wc[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_7,p_7] = sc.stats.ttest_ind(t_f1[a], t_f1[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_8,p_8] = sc.stats.ttest_ind(t_f2[a], t_f2[b], equal_var = False, axis=0) \n",
    "\n",
    "        [s_9,p_9] = sc.stats.ttest_ind(t_f3[a], t_f3[b], equal_var = False, axis=0) \n",
    "\n",
    "        p_0_fdr = sm.stats.multitest.multipletests(p_0,alpha=0.05,method='fdr_bh')\n",
    "        p_1_fdr = sm.stats.multitest.multipletests(p_1,alpha=0.05,method='fdr_bh')\n",
    "        p_2_fdr = sm.stats.multitest.multipletests(p_2,alpha=0.05,method='fdr_bh')\n",
    "        p_3_fdr = sm.stats.multitest.multipletests(p_3,alpha=0.05,method='fdr_bh')\n",
    "        p_4_fdr = sm.stats.multitest.multipletests(p_4,alpha=0.05,method='fdr_bh')\n",
    "        p_5_fdr = sm.stats.multitest.multipletests(p_5,alpha=0.05,method='fdr_bh')\n",
    "        p_6_fdr = sm.stats.multitest.multipletests(p_6,alpha=0.05,method='fdr_bh')\n",
    "        p_7_fdr = sm.stats.multitest.multipletests(p_7,alpha=0.05,method='fdr_bh')\n",
    "        p_8_fdr = sm.stats.multitest.multipletests(p_8,alpha=0.05,method='fdr_bh')\n",
    "        p_9_fdr = sm.stats.multitest.multipletests(p_9,alpha=0.05,method='fdr_bh')\n",
    "\n",
    "        BMI_fdr.append(p_0_fdr[1][0])\n",
    "        WHR_fdr.append(p_1_fdr[1][0])\n",
    "        EDEQ_R_fdr.append(p_2_fdr[1][0])\n",
    "        EDEQ_Con_fdr.append(p_3_fdr[1][0])\n",
    "        EDEQ_E_Con_fdr.append(p_4_fdr[1][0])\n",
    "        EDEQ_S_Con_fdr.append(p_5_fdr[1][0])\n",
    "        EDEQ_W_Con_fdr.append(p_6_fdr[1][0])\n",
    "        TFEQ_F1_fdr.append(p_7_fdr[1][0])\n",
    "        TFEQ_F2_fdr.append(p_8_fdr[1][0])\n",
    "        TFEQ_F3_fdr.append(p_9_fdr[1][0])\n",
    "\n",
    "    result = {'BMI' : [np.round(i,4) for i in BMI_fdr], \n",
    "                   'WHR' : [np.round(i,4) for i in WHR_fdr], \n",
    "                   'EDEQ_R' : [np.round(i,4) for i in EDEQ_R_fdr],\n",
    "                   'EDEQ_Con' : [np.round(i,4) for i in EDEQ_Con_fdr], \n",
    "                   'EDEQ_E_Con' : [np.round(i,4) for i in EDEQ_E_Con_fdr], \n",
    "                   'EDEQ_S_Con' : [np.round(i,4) for i in EDEQ_S_Con_fdr],\n",
    "                   'EDEQ_W_Con' : [np.round(i,4) for i in EDEQ_W_Con_fdr], \n",
    "                   'TFEQ_F1' : [np.round(i,4) for i in TFEQ_F1_fdr], \n",
    "                   'TFEQ_F2' : [np.round(i,4) for i in TFEQ_F2_fdr],\n",
    "                   'TFEQ_F3' : [np.round(i,4) for i in TFEQ_F3_fdr]}\n",
    "    \n",
    "    if save:\n",
    "        np.save(join(save_path,trial,'stat_result.npy'), result)\n",
    "\n",
    "    if result_show:\n",
    "        for key, val in result.items():\n",
    "            print(f'{key}    :    {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-cinema",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subtype score mean std\n",
    "\n",
    "def subtype_score(cluster_label, subj_idx):\n",
    "    subtype_idx = []\n",
    "    for i in range(cluster_label.max()+1):\n",
    "        subtype_idx.append(np.where(cluster_label==i)[0])\n",
    "\n",
    "    score_label = ['BMI', 'TFEQ_F1', 'TFEQ_F2', 'TFEQ_F3']\n",
    "    for i, s in enumerate([BMI, TFEQ_F1, TFEQ_F2, TFEQ_F3]):\n",
    "        a = np.array(s)[subj_idx][subtype_idx[0]]\n",
    "        b = np.array(s)[subj_idx][subtype_idx[1]]\n",
    "        c = np.array(s)[subj_idx][subtype_idx[2]]\n",
    "\n",
    "        print(score_label[i])\n",
    "        print(f'{np.round(a.mean(),2)} +- {np.round(a.std(),2)}')\n",
    "        print(f'{np.round(b.mean(),2)} +- {np.round(b.std(),2)}')\n",
    "        print(f'{np.round(c.mean(),2)} +- {np.round(c.std(),2)}')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-emerald",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_subj(cluster_label):\n",
    "    idx = []\n",
    "    for i in range(cluster_label.max()+1):\n",
    "        print(f'label {i} :', len(np.where(cluster_label==i)[0]))\n",
    "        idx.append(np.where(cluster_label==i)[0])\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_ttest(score_data, otest_idx, cluster_label, random_state):\n",
    "\n",
    "    from sklearn.utils import shuffle\n",
    "    \n",
    "    idx = otest_idx\n",
    "    label = cluster_label\n",
    "\n",
    "    idx1 = idx[np.where(label==0)[0]]\n",
    "    idx2 = idx[np.where(label==1)[0]]\n",
    "    idx3 = idx[np.where(label==2)[0]]\n",
    "\n",
    "    score = np.array(score_data)\n",
    "    \n",
    "    idx_list1 = [idx1, idx1, idx2]\n",
    "    idx_list2 = [idx2, idx3, idx3]\n",
    "    \n",
    "    p_list = []\n",
    "    \n",
    "    for num in range(3):\n",
    "\n",
    "        x_data = score[idx_list1[num]]\n",
    "        y_data = score[idx_list2[num]]\n",
    "\n",
    "        n_perm = 1000\n",
    "        all_t = np.zeros(n_perm)\n",
    "\n",
    "#         print('T-test\\n')\n",
    "        observe = sc.stats.ttest_ind(x_data,y_data)[0]\n",
    "\n",
    "        X = np.concatenate((x_data,y_data))\n",
    "        z = np.concatenate((np.ones(x_data.shape[0]),np.zeros(y_data.shape[0])))\n",
    "\n",
    "        for i in range(n_perm):\n",
    "            z = shuffle(z, random_state = random_state) # main perm 2, 30% 10, 20% 0, Gau 15,AE_dropx 15, AE_420 15, AE_120 15, ME 16, gradient 16, boot_470 58, boot_562 6, boot_626 4, Lemon 44\n",
    "            xn = X[z==1]\n",
    "            yn = X[z==0]\n",
    "            all_t[i] = sc.stats.ttest_ind(xn,yn)[0]\n",
    "        \n",
    "        pval = np.array((abs(np.array(all_t)) >= abs(observe))).mean()\n",
    "        print('p value : ', pval)\n",
    "        p_list.append(pval)\n",
    "\n",
    "#         plt.figure(num, (5,5))\n",
    "#         plt.hist(all_t, bins = 50)\n",
    "#         plt.axvline(observe, color = 'r', linestyle = '--')\n",
    "#         plt.xlabel('t value')\n",
    "#         plt.ylabel('Frequency')\n",
    "    print('')\n",
    "    return np.array(p_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
